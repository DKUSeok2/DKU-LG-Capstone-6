{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 2.0.1\n",
      "Scikit-learn version: 1.6.1\n",
      "Pandas version: 2.2.3\n",
      "Matplotlib version: 3.10.0\n",
      "Seaborn version: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# 각 라이브러리 버전 출력\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Scikit-learn version:\", sklearn.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "print(\"Seaborn version:\", sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import  OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ '대리모 여부' 결측값을 최빈값 (0.0) 으로 대체 완료!\n",
      "✅ 컬럼 삭제 완료: ['PGD 시술 여부', 'PGS 시술 여부', '난자 해동 경과일', '배아 해동 경과일']\n",
      "✅ '난자 채취 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '난자 혼합 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '배아 이식 경과일' 결측값을 중앙값 (3.0) 으로 대체 완료!\n",
      "50    50\n",
      "51    51\n",
      "52    52\n",
      "53    53\n",
      "54    54\n",
      "55    55\n",
      "56    56\n",
      "57    57\n",
      "58    58\n",
      "59    59\n",
      "60    60\n",
      "61    61\n",
      "62    62\n",
      "63    63\n",
      "64    64\n",
      "65    65\n",
      "66    66\n",
      "67    67\n",
      "68    68\n",
      "69    69\n",
      "70    70\n",
      "71    71\n",
      "72    72\n",
      "73    73\n",
      "74    74\n",
      "75    75\n",
      "76    76\n",
      "77    77\n",
      "78    78\n",
      "79    79\n",
      "80    80\n",
      "81    81\n",
      "82    82\n",
      "83    83\n",
      "84    84\n",
      "85    85\n",
      "86    86\n",
      "87    87\n",
      "88    88\n",
      "89    89\n",
      "90    90\n",
      "91    91\n",
      "92    92\n",
      "93    93\n",
      "94    94\n",
      "95    95\n",
      "96    96\n",
      "97    97\n",
      "98    98\n",
      "99    99\n",
      "Name: index, dtype: int64\n",
      "✅ '대리모 여부' 결측값을 최빈값 (0.0) 으로 대체 완료!\n",
      "✅ 컬럼 삭제 완료: ['PGD 시술 여부', 'PGS 시술 여부', '난자 해동 경과일', '배아 해동 경과일']\n",
      "✅ '난자 채취 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '난자 혼합 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '배아 이식 경과일' 결측값을 중앙값 (3.0) 으로 대체 완료!\n",
      "50    50\n",
      "51    51\n",
      "52    52\n",
      "53    53\n",
      "54    54\n",
      "55    55\n",
      "56    56\n",
      "57    57\n",
      "58    58\n",
      "59    59\n",
      "60    60\n",
      "61    61\n",
      "62    62\n",
      "63    63\n",
      "64    64\n",
      "65    65\n",
      "66    66\n",
      "67    67\n",
      "68    68\n",
      "69    69\n",
      "70    70\n",
      "71    71\n",
      "72    72\n",
      "73    73\n",
      "74    74\n",
      "75    75\n",
      "76    76\n",
      "77    77\n",
      "78    78\n",
      "79    79\n",
      "80    80\n",
      "81    81\n",
      "82    82\n",
      "83    83\n",
      "84    84\n",
      "85    85\n",
      "86    86\n",
      "87    87\n",
      "88    88\n",
      "89    89\n",
      "90    90\n",
      "91    91\n",
      "92    92\n",
      "93    93\n",
      "94    94\n",
      "95    95\n",
      "96    96\n",
      "97    97\n",
      "98    98\n",
      "99    99\n",
      "Name: index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 현재 작업 디렉토리 경로를 가져와 shared codes 폴더의 위치를 sys.path에 추가합니다.\n",
    "# sys.path에 추가된 경로에 있는 py 폴더는 임포트할 수 있다.\n",
    "current_dir = os.getcwd()\n",
    "shared_codes_dir = os.path.join(current_dir, '../shared codes')\n",
    "sys.path.append(shared_codes_dir)\n",
    "\n",
    "\n",
    "# cover_nan 모듈을 임포트\n",
    "from cover_nan_0215_dahun import missing_value_removal_function\n",
    "\n",
    "# 원본 train 데이터 로드\n",
    "train = pd.read_csv(\"../shared codes/data/train.csv\")\n",
    "test = pd.read_csv(\"../shared codes/data/test.csv\")\n",
    "\n",
    "# missing_value_removal_function 사용\n",
    "train_young, train_middle, train_old, train_unknown = missing_value_removal_function(train)\n",
    "test_young, test_middle, test_old, test_unknown = missing_value_removal_function(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/lg_aimers/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "def data_preprocessing(train, test):\n",
    "    index_train = train['index']\n",
    "    X = train.drop(['임신 성공 여부', 'index'], axis=1)\n",
    "    y = train['임신 성공 여부']\n",
    "\n",
    "    index_test = test['index']\n",
    "    test = test.drop('index', axis=1)\n",
    "\n",
    "    #Data Pre-processing\n",
    "    # Categorical(범주형) 칼럼 찾기\n",
    "    categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "    X_train_encoded = X.copy()\n",
    "    X_train_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "    X_test_encoded = test.copy()\n",
    "    X_test_encoded[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])\n",
    "\n",
    "    columns_to_drop = [\n",
    "            \"남성 주 불임 원인\",\n",
    "            \"남성 부 불임 원인\",\n",
    "            \"불임 원인 - 정자 농도\",\n",
    "            \"불임 원인 - 정자 면역학적 요인\",\n",
    "            \"불임 원인 - 정자 운동성\",\n",
    "            \"불임 원인 - 정자 형태\",\n",
    "            '배란 유도 유형'\n",
    "    ]\n",
    "    X_train_encoded = X_train_encoded.drop(columns = columns_to_drop)    \n",
    "    X_test_encoded = X_test_encoded.drop(columns = columns_to_drop)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # 데이터 정규화 (X_train_encoded & X_test_encoded)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "    X_test_scaled = scaler.transform(X_test_encoded)  # 동일한 스케일 적용\n",
    "\n",
    "    # DataFrame 변환 (Feature 이름 유지)\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X_train_scaled.shape[1])]\n",
    "    X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "    X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "\n",
    "    # 상관 행렬 계산\n",
    "    correlation_matrix_train = X_train_scaled_df.corr()\n",
    "\n",
    "    # 다중 공선성이 높은 칼럼 찾기 (절대 상관 계수가 0.8 이상)\n",
    "    threshold = 0.8\n",
    "    high_corr_features = set()\n",
    "\n",
    "    for i in range(len(feature_names)):\n",
    "        for j in range(i + 1, len(feature_names)):\n",
    "            if abs(correlation_matrix_train.iloc[i, j]) > threshold:\n",
    "                high_corr_features.add(feature_names[j])  # 공선성이 높은 컬럼 추가\n",
    "\n",
    "    # 다중 공선성이 높은 컬럼 제거\n",
    "    X_train_encoded = X_train_scaled_df.drop(columns=high_corr_features, errors='ignore')\n",
    "    X_test_encoded = X_test_scaled_df.drop(columns=high_corr_features, errors='ignore')\n",
    "\n",
    "    X_train_encoded['index'] = index_train\n",
    "    X_test_encoded['index'] = index_test\n",
    "\n",
    "    return X_train_encoded, X_test_encoded, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_models_and_get_best_params(X_train_encoded, y):\n",
    "\n",
    "    def optimize_xgboost(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 5)\n",
    "        }\n",
    "        model = XGBClassifier(**params, random_state=42, eval_metric=\"logloss\")\n",
    "        scores = cross_val_score(model, X_train_encoded, y, cv=5, scoring=\"roc_auc\")\n",
    "        return np.mean(scores)\n",
    "\n",
    "\n",
    "    def optimize_lightgbm(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 50),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=42)\n",
    "        scores = cross_val_score(model, X_train_encoded, y, cv=5, scoring=\"roc_auc\")  \n",
    "        return np.mean(scores)\n",
    "\n",
    "    def optimize_random_forest(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 3, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4)\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "        scores = cross_val_score(model, X_train_encoded, y, cv=5, scoring=\"roc_auc\")  \n",
    "        return np.mean(scores)\n",
    "\n",
    "    # Optuna 스터디 실행\n",
    "    print(\"Optimizing XGBoost...\")\n",
    "    xgb_study = optuna.create_study(direction=\"maximize\")\n",
    "    xgb_study.optimize(optimize_xgboost, n_trials=5)\n",
    "    best_xgb_params = xgb_study.best_params\n",
    "\n",
    "    print(\"Optimizing LightGBM...\")\n",
    "    lgbm_study = optuna.create_study(direction=\"maximize\")\n",
    "    lgbm_study.optimize(optimize_lightgbm, n_trials=5)\n",
    "    best_lgbm_params = lgbm_study.best_params\n",
    "\n",
    "    print(\"Optimizing RandomForest...\")\n",
    "    rf_study = optuna.create_study(direction=\"maximize\")\n",
    "    rf_study.optimize(optimize_random_forest, n_trials=2)\n",
    "    best_rf_params = rf_study.best_params\n",
    "\n",
    "    params = [best_xgb_params, best_lgbm_params, best_rf_params]\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble_model(X_train_encoded, y, X_test_encoded, params):\n",
    "\n",
    "    \n",
    "    # best params\n",
    "    best_xgb_params, best_lgbm_params, best_rf_params = params\n",
    "\n",
    "    # 최적화된 모델 생성\n",
    "    xgb_model = XGBClassifier(**best_xgb_params, random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    lgbm_model = LGBMClassifier(**best_lgbm_params, random_state=42)\n",
    "    rf_model = RandomForestClassifier(**best_rf_params, random_state=42)\n",
    "\n",
    "    # Soft Voting 앙상블\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"xgb\", xgb_model),\n",
    "            (\"lgbm\", lgbm_model),\n",
    "            (\"rf\", rf_model)\n",
    "        ],\n",
    "        voting=\"soft\"\n",
    "    )\n",
    "\n",
    "    # 전체 데이터로 학습\n",
    "    ensemble_model.fit(X_train_encoded, y)\n",
    "\n",
    "    pred_proba = ensemble_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame()\n",
    "    submission['probability'] = pred_proba\n",
    "    submission['index'] = X_test_encoded['index']\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded_young, X_test_encoded_young, y_young = data_preprocessing(train_young, test_young)\n",
    "X_train_encoded_middle, X_test_encoded_middle, y_middle = data_preprocessing(train_middle, test_middle)\n",
    "X_train_encoded_old, X_test_encoded_old, y_old = data_preprocessing(train_old, test_old)\n",
    "\n",
    "params_young = optimize_models_and_get_best_params(X_train_encoded_young, y_young)\n",
    "params_middle = optimize_models_and_get_best_params(X_train_encoded_middle, y_middle)\n",
    "params_old = optimize_models_and_get_best_params(X_train_encoded_old, y_old)\n",
    "\n",
    "submission_young = train_ensemble_model(X_train_encoded_young, y_young, X_test_encoded_young, params_young)\n",
    "submission_middle = train_ensemble_model(X_train_encoded_middle, y_middle, X_test_encoded_middle, params_middle)\n",
    "submission_old = train_ensemble_model(X_train_encoded_old, y_old, X_test_encoded_old, params_old)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_unknown의 데이터 개수만큼 0으로 채워진 submission_unknown 생성\n",
    "submission_unknown = pd.DataFrame()\n",
    "submission_unknown['probability'] = [0] * len(test_unknown)\n",
    "submission_unknown['index'] = test_unknown.index\n",
    "\n",
    "submission = pd.concat([submission_young, submission_middle, submission_old, submission_unknown])\n",
    "\n",
    "submission = submission.sort_values('index')\n",
    "# submission = submission.drop(columns=['index'])\n",
    "\n",
    "home_dir = '/Users/downy/Documents/2025 LG aimers/DKU-LG-Capstone-6'\n",
    "sample_submission = pd.read_csv(home_dir + '/shared codes/data/sample_submission.csv')\n",
    "\n",
    "submission['ID'] = sample_submission['ID']\n",
    "\n",
    "# print(sample_submission[60000:60050])\n",
    "\n",
    "submission = submission[['ID', 'probability']]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0</td>\n",
       "      <td>89178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0</td>\n",
       "      <td>89298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0</td>\n",
       "      <td>89484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0</td>\n",
       "      <td>89699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>89752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  index\n",
       "0              0    749\n",
       "1              0    756\n",
       "2              0    810\n",
       "3              0   2017\n",
       "4              0   2213\n",
       "..           ...    ...\n",
       "230            0  89178\n",
       "231            0  89298\n",
       "232            0  89484\n",
       "233            0  89699\n",
       "234            0  89752\n",
       "\n",
       "[235 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_unknown['index'] = test_unknown.index\n",
    "submission_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020112</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.463508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.117618</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058717</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406301</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability  index\n",
       "0       0.020112    0.0\n",
       "1       0.463508    1.0\n",
       "2       0.117618    2.0\n",
       "3       0.058717    3.0\n",
       "4       0.406301    4.0\n",
       "..           ...    ...\n",
       "230     0.000000    NaN\n",
       "231     0.000000    NaN\n",
       "232     0.000000    NaN\n",
       "233     0.000000    NaN\n",
       "234     0.000000    NaN\n",
       "\n",
       "[90067 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['ID'] = sample_submission['ID']\n",
    "\n",
    "# print(sample_submission[60000:60050])\n",
    "\n",
    "submission = submission[['ID', 'probability']]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['ID', 'probability']]\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID  probability\n",
      "60000  TEST_60000          0.0\n",
      "60001  TEST_60001          0.0\n",
      "60002  TEST_60002          0.0\n",
      "60003  TEST_60003          0.0\n",
      "60004  TEST_60004          0.0\n",
      "60005  TEST_60005          0.0\n",
      "60006  TEST_60006          0.0\n",
      "60007  TEST_60007          0.0\n",
      "60008  TEST_60008          0.0\n",
      "60009  TEST_60009          0.0\n",
      "60010  TEST_60010          0.0\n",
      "60011  TEST_60011          0.0\n",
      "60012  TEST_60012          0.0\n",
      "60013  TEST_60013          0.0\n",
      "60014  TEST_60014          0.0\n",
      "60015  TEST_60015          0.0\n",
      "60016  TEST_60016          0.0\n",
      "60017  TEST_60017          0.0\n",
      "60018  TEST_60018          0.0\n",
      "60019  TEST_60019          0.0\n",
      "60020  TEST_60020          0.0\n",
      "60021  TEST_60021          0.0\n",
      "60022  TEST_60022          0.0\n",
      "60023  TEST_60023          0.0\n",
      "60024  TEST_60024          0.0\n",
      "60025  TEST_60025          0.0\n",
      "60026  TEST_60026          0.0\n",
      "60027  TEST_60027          0.0\n",
      "60028  TEST_60028          0.0\n",
      "60029  TEST_60029          0.0\n",
      "60030  TEST_60030          0.0\n",
      "60031  TEST_60031          0.0\n",
      "60032  TEST_60032          0.0\n",
      "60033  TEST_60033          0.0\n",
      "60034  TEST_60034          0.0\n",
      "60035  TEST_60035          0.0\n",
      "60036  TEST_60036          0.0\n",
      "60037  TEST_60037          0.0\n",
      "60038  TEST_60038          0.0\n",
      "60039  TEST_60039          0.0\n",
      "60040  TEST_60040          0.0\n",
      "60041  TEST_60041          0.0\n",
      "60042  TEST_60042          0.0\n",
      "60043  TEST_60043          0.0\n",
      "60044  TEST_60044          0.0\n",
      "60045  TEST_60045          0.0\n",
      "60046  TEST_60046          0.0\n",
      "60047  TEST_60047          0.0\n",
      "60048  TEST_60048          0.0\n",
      "60049  TEST_60049          0.0\n"
     ]
    }
   ],
   "source": [
    "home_dir = '/Users/downy/Documents/2025 LG aimers/DKU-LG-Capstone-6'\n",
    "sample_submission = pd.read_csv(home_dir + '/shared codes/data/sample_submission.csv')\n",
    "\n",
    "print(sample_submission[60000:60050])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg_aimers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
