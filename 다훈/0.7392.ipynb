{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import  OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ '대리모 여부' 결측값을 최빈값 (0.0) 으로 대체 완료!\n",
      "✅ 컬럼 삭제 완료: ['PGD 시술 여부', 'PGS 시술 여부', '난자 해동 경과일', '배아 해동 경과일']\n",
      "✅ '난자 채취 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '난자 혼합 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '배아 이식 경과일' 결측값을 중앙값 (3.0) 으로 대체 완료!\n",
      "✅ '대리모 여부' 결측값을 최빈값 (0.0) 으로 대체 완료!\n",
      "✅ 컬럼 삭제 완료: ['PGD 시술 여부', 'PGS 시술 여부', '난자 해동 경과일', '배아 해동 경과일']\n",
      "✅ '난자 채취 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '난자 혼합 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '배아 이식 경과일' 결측값을 중앙값 (3.0) 으로 대체 완료!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 현재 작업 디렉토리 경로를 가져와 shared codes 폴더의 위치를 sys.path에 추가합니다.\n",
    "# sys.path에 추가된 경로에 있는 py 폴더는 임포트할 수 있다.\n",
    "current_dir = os.getcwd()\n",
    "shared_codes_dir = os.path.join(current_dir, '../shared codes')\n",
    "sys.path.append(shared_codes_dir)\n",
    "\n",
    "\n",
    "# cover_nan 모듈을 임포트\n",
    "from cover_nan_0215_dahun import missing_value_removal_function\n",
    "\n",
    "# 원본 train 데이터 로드\n",
    "train = pd.read_csv(\"../shared codes/data/train.csv\")\n",
    "test = pd.read_csv(\"../shared codes/data/test.csv\")\n",
    "\n",
    "# missing_value_removal_function 사용\n",
    "train_young, train_middle, train_old, train_unknown = missing_value_removal_function(train)\n",
    "test_young, test_middle, test_old, test_unknown = missing_value_removal_function(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(train, test):\n",
    "    index_train = train['idx']\n",
    "    X = train.drop(['임신 성공 여부', 'idx'], axis=1)\n",
    "    y = train['임신 성공 여부']\n",
    "\n",
    "    # index_test = test['idx']\n",
    "    index_test = test['idx'].copy()  # Ensure a copy is made to prevent any shared memory issues\n",
    "    test = test.drop('idx', axis=1)\n",
    "\n",
    "    #Data Pre-processing\n",
    "    # Categorical(범주형) 칼럼 찾기\n",
    "    categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # 데이터 인코딩\n",
    "    ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "    X_train_encoded = X.copy()\n",
    "    X_train_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "    X_test_encoded = test.copy()\n",
    "    X_test_encoded[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])\n",
    "\n",
    "    # 불필요한 칼럼 삭제\n",
    "    columns_to_drop = [\n",
    "            \"남성 주 불임 원인\",\n",
    "            \"남성 부 불임 원인\",\n",
    "            \"불임 원인 - 정자 농도\",\n",
    "            \"불임 원인 - 정자 면역학적 요인\",\n",
    "            \"불임 원인 - 정자 운동성\",\n",
    "            \"불임 원인 - 정자 형태\",\n",
    "            '배란 유도 유형'\n",
    "    ]\n",
    "    X_train_encoded = X_train_encoded.drop(columns = columns_to_drop)    \n",
    "    X_test_encoded = X_test_encoded.drop(columns = columns_to_drop)\n",
    "    \n",
    "\n",
    "    # 데이터 정규화 (X_train_encoded & X_test_encoded)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "    X_test_scaled = scaler.transform(X_test_encoded)  # 동일한 스케일 적용\n",
    "\n",
    "    # DataFrame 변환 (Feature 이름 유지)\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X_train_scaled.shape[1])]\n",
    "    X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "    X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "\n",
    "    # 상관 행렬 계산\n",
    "    correlation_matrix_train = X_train_scaled_df.corr()\n",
    "\n",
    "    # 다중 공선성이 높은 칼럼 찾기 (절대 상관 계수가 0.8 이상)\n",
    "    threshold = 0.8\n",
    "    high_corr_features = set()\n",
    "\n",
    "    for i in range(len(feature_names)):\n",
    "        for j in range(i + 1, len(feature_names)):\n",
    "            if abs(correlation_matrix_train.iloc[i, j]) > threshold:\n",
    "                high_corr_features.add(feature_names[j])  # 공선성이 높은 컬럼 추가\n",
    "\n",
    "    # 다중 공선성이 높은 컬럼 제거\n",
    "    X_train_encoded = X_train_scaled_df.drop(columns=high_corr_features, errors='ignore')\n",
    "    X_test_encoded = X_test_scaled_df.drop(columns=high_corr_features, errors='ignore')\n",
    "\n",
    "\n",
    "    X_train_encoded['idx'] = index_train.reset_index(drop=True)\n",
    "    X_test_encoded['idx'] = index_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    return X_train_encoded, X_test_encoded, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ '대리모 여부' 결측값을 최빈값 (0.0) 으로 대체 완료!\n",
      "✅ 컬럼 삭제 완료: ['PGD 시술 여부', 'PGS 시술 여부', '난자 해동 경과일', '배아 해동 경과일']\n",
      "✅ '난자 채취 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '난자 혼합 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '배아 이식 경과일' 결측값을 중앙값 (3.0) 으로 대체 완료!\n",
      "✅ '대리모 여부' 결측값을 최빈값 (0.0) 으로 대체 완료!\n",
      "✅ 컬럼 삭제 완료: ['PGD 시술 여부', 'PGS 시술 여부', '난자 해동 경과일', '배아 해동 경과일']\n",
      "✅ '난자 채취 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '난자 혼합 경과일' 결측값을 중앙값 (0.0) 으로 대체 완료!\n",
      "✅ '배아 이식 경과일' 결측값을 중앙값 (3.0) 으로 대체 완료!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m train_young, train_middle, train_old, train_unknown \u001b[38;5;241m=\u001b[39m missing_value_removal_function(train)\n\u001b[1;32m      2\u001b[0m test_young, test_middle, test_old, test_unknown \u001b[38;5;241m=\u001b[39m missing_value_removal_function(test)\n\u001b[0;32m----> 4\u001b[0m X_train_encoded_young, X_test_encoded_young, y_young \u001b[38;5;241m=\u001b[39m \u001b[43mdata_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_young\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_young\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m X_train_encoded_middle, X_test_encoded_middle, y_middle \u001b[38;5;241m=\u001b[39m data_preprocessing(train_middle, test_middle)\n\u001b[1;32m      6\u001b[0m X_train_encoded_old, X_test_encoded_old, y_old \u001b[38;5;241m=\u001b[39m data_preprocessing(train_old, test_old)\n",
      "Cell \u001b[0;32mIn[31], line 48\u001b[0m, in \u001b[0;36mdata_preprocessing\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m     40\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test_encoded)  \u001b[38;5;66;03m# 동일한 스케일 적용\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# DataFrame 변환 (Feature 이름 유지)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# feature_names = [f\"Feature_{i}\" for i in range(X_train_scaled.shape[1])]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_names)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_names)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 상관 행렬 계산\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m correlation_matrix_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_scaled_df\u001b[49m\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 다중 공선성이 높은 칼럼 찾기 (절대 상관 계수가 0.8 이상)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_young, train_middle, train_old, train_unknown = missing_value_removal_function(train)\n",
    "test_young, test_middle, test_old, test_unknown = missing_value_removal_function(test)\n",
    "\n",
    "X_train_encoded_young, X_test_encoded_young, y_young = data_preprocessing(train_young, test_young)\n",
    "X_train_encoded_middle, X_test_encoded_middle, y_middle = data_preprocessing(train_middle, test_middle)\n",
    "X_train_encoded_old, X_test_encoded_old, y_old = data_preprocessing(train_old, test_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_37</th>\n",
       "      <th>Feature_38</th>\n",
       "      <th>Feature_41</th>\n",
       "      <th>Feature_42</th>\n",
       "      <th>Feature_44</th>\n",
       "      <th>Feature_45</th>\n",
       "      <th>Feature_46</th>\n",
       "      <th>Feature_47</th>\n",
       "      <th>Feature_48</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.732036</td>\n",
       "      <td>1.517565</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>-0.910711</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>-0.680849</td>\n",
       "      <td>-0.15317</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.072521</td>\n",
       "      <td>-0.511059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316811</td>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.217518</td>\n",
       "      <td>-0.413544</td>\n",
       "      <td>-0.135082</td>\n",
       "      <td>-0.081968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04008</td>\n",
       "      <td>-0.251576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.732005</td>\n",
       "      <td>0.022890</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>0.703631</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>-0.680849</td>\n",
       "      <td>-0.15317</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.072521</td>\n",
       "      <td>-0.511059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192517</td>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.217518</td>\n",
       "      <td>-0.413544</td>\n",
       "      <td>-0.135082</td>\n",
       "      <td>-0.081968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04008</td>\n",
       "      <td>-0.887744</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.731975</td>\n",
       "      <td>0.022890</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>-0.910711</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>-0.680849</td>\n",
       "      <td>-0.15317</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.072521</td>\n",
       "      <td>-0.511059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316811</td>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.217518</td>\n",
       "      <td>-0.413544</td>\n",
       "      <td>-0.135082</td>\n",
       "      <td>-0.081968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04008</td>\n",
       "      <td>-0.251576</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.731944</td>\n",
       "      <td>-0.475335</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>-0.910711</td>\n",
       "      <td>-1.745589</td>\n",
       "      <td>1.468755</td>\n",
       "      <td>-0.15317</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.072521</td>\n",
       "      <td>-0.511059</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.186865</td>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.217518</td>\n",
       "      <td>-0.413544</td>\n",
       "      <td>-0.135082</td>\n",
       "      <td>-0.081968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04008</td>\n",
       "      <td>-0.887744</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.731914</td>\n",
       "      <td>1.019340</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>0.703631</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>-0.680849</td>\n",
       "      <td>-0.15317</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.072521</td>\n",
       "      <td>1.956722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.938278</td>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.217518</td>\n",
       "      <td>-0.413544</td>\n",
       "      <td>-0.135082</td>\n",
       "      <td>-0.081968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04008</td>\n",
       "      <td>-0.251576</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113722</th>\n",
       "      <td>1.731914</td>\n",
       "      <td>0.521115</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>-0.910711</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>-0.680849</td>\n",
       "      <td>-0.15317</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.072521</td>\n",
       "      <td>-0.511059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565398</td>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.217518</td>\n",
       "      <td>-0.413544</td>\n",
       "      <td>-0.135082</td>\n",
       "      <td>-0.081968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04008</td>\n",
       "      <td>-0.251576</td>\n",
       "      <td>256340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113723</th>\n",
       "      <td>1.731944</td>\n",
       "      <td>1.019340</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>-0.910711</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>1.468755</td>\n",
       "      <td>-0.15317</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.072521</td>\n",
       "      <td>-0.511059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056070</td>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.217518</td>\n",
       "      <td>-0.413544</td>\n",
       "      <td>-0.135082</td>\n",
       "      <td>-0.081968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04008</td>\n",
       "      <td>1.020760</td>\n",
       "      <td>256343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113724</th>\n",
       "      <td>1.731975</td>\n",
       "      <td>1.517565</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>0.703631</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>1.468755</td>\n",
       "      <td>-0.15317</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.072521</td>\n",
       "      <td>-0.511059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304656</td>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.217518</td>\n",
       "      <td>-0.413544</td>\n",
       "      <td>-0.135082</td>\n",
       "      <td>-0.081968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04008</td>\n",
       "      <td>-0.887744</td>\n",
       "      <td>256344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113725</th>\n",
       "      <td>1.732005</td>\n",
       "      <td>-1.471785</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>-0.910711</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>-0.680849</td>\n",
       "      <td>-0.15317</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.072521</td>\n",
       "      <td>-0.511059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677537</td>\n",
       "      <td>-0.074932</td>\n",
       "      <td>2.038879</td>\n",
       "      <td>-0.413544</td>\n",
       "      <td>-0.135082</td>\n",
       "      <td>-0.081968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04008</td>\n",
       "      <td>1.020760</td>\n",
       "      <td>256345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113726</th>\n",
       "      <td>1.732036</td>\n",
       "      <td>1.019340</td>\n",
       "      <td>0.136191</td>\n",
       "      <td>-0.910711</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>-0.680849</td>\n",
       "      <td>-0.15317</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.072521</td>\n",
       "      <td>1.956722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180363</td>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.217518</td>\n",
       "      <td>-0.413544</td>\n",
       "      <td>-0.135082</td>\n",
       "      <td>-0.081968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04008</td>\n",
       "      <td>1.020760</td>\n",
       "      <td>256346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113727 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
       "0       -1.732036   1.517565   0.136191  -0.910711   0.572873  -0.680849   \n",
       "1       -1.732005   0.022890   0.136191   0.703631   0.572873  -0.680849   \n",
       "2       -1.731975   0.022890   0.136191  -0.910711   0.572873  -0.680849   \n",
       "3       -1.731944  -0.475335   0.136191  -0.910711  -1.745589   1.468755   \n",
       "4       -1.731914   1.019340   0.136191   0.703631   0.572873  -0.680849   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "113722   1.731914   0.521115   0.136191  -0.910711   0.572873  -0.680849   \n",
       "113723   1.731944   1.019340   0.136191  -0.910711   0.572873   1.468755   \n",
       "113724   1.731975   1.517565   0.136191   0.703631   0.572873   1.468755   \n",
       "113725   1.732005  -1.471785   0.136191  -0.910711   0.572873  -0.680849   \n",
       "113726   1.732036   1.019340   0.136191  -0.910711   0.572873  -0.680849   \n",
       "\n",
       "        Feature_6  Feature_7  Feature_9  Feature_10  ...  Feature_37  \\\n",
       "0        -0.15317  -0.086829  -0.072521   -0.511059  ...   -0.316811   \n",
       "1        -0.15317  -0.086829  -0.072521   -0.511059  ...   -0.192517   \n",
       "2        -0.15317  -0.086829  -0.072521   -0.511059  ...   -0.316811   \n",
       "3        -0.15317  -0.086829  -0.072521   -0.511059  ...   -1.186865   \n",
       "4        -0.15317  -0.086829  -0.072521    1.956722  ...   -0.938278   \n",
       "...           ...        ...        ...         ...  ...         ...   \n",
       "113722   -0.15317  -0.086829  -0.072521   -0.511059  ...   -0.565398   \n",
       "113723   -0.15317  -0.086829  -0.072521   -0.511059  ...    0.056070   \n",
       "113724   -0.15317  -0.086829  -0.072521   -0.511059  ...    0.304656   \n",
       "113725   -0.15317  -0.086829  -0.072521   -0.511059  ...    0.677537   \n",
       "113726   -0.15317  -0.086829  -0.072521    1.956722  ...    0.180363   \n",
       "\n",
       "        Feature_38  Feature_41  Feature_42  Feature_44  Feature_45  \\\n",
       "0        -0.074932   -0.217518   -0.413544   -0.135082   -0.081968   \n",
       "1        -0.074932   -0.217518   -0.413544   -0.135082   -0.081968   \n",
       "2        -0.074932   -0.217518   -0.413544   -0.135082   -0.081968   \n",
       "3        -0.074932   -0.217518   -0.413544   -0.135082   -0.081968   \n",
       "4        -0.074932   -0.217518   -0.413544   -0.135082   -0.081968   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "113722   -0.074932   -0.217518   -0.413544   -0.135082   -0.081968   \n",
       "113723   -0.074932   -0.217518   -0.413544   -0.135082   -0.081968   \n",
       "113724   -0.074932   -0.217518   -0.413544   -0.135082   -0.081968   \n",
       "113725   -0.074932    2.038879   -0.413544   -0.135082   -0.081968   \n",
       "113726   -0.074932   -0.217518   -0.413544   -0.135082   -0.081968   \n",
       "\n",
       "        Feature_46  Feature_47  Feature_48     idx  \n",
       "0              0.0    -0.04008   -0.251576       0  \n",
       "1              0.0    -0.04008   -0.887744       2  \n",
       "2              0.0    -0.04008   -0.251576       4  \n",
       "3              0.0    -0.04008   -0.887744       6  \n",
       "4              0.0    -0.04008   -0.251576       9  \n",
       "...            ...         ...         ...     ...  \n",
       "113722         0.0    -0.04008   -0.251576  256340  \n",
       "113723         0.0    -0.04008    1.020760  256343  \n",
       "113724         0.0    -0.04008   -0.887744  256344  \n",
       "113725         0.0    -0.04008    1.020760  256345  \n",
       "113726         0.0    -0.04008    1.020760  256346  \n",
       "\n",
       "[113727 rows x 39 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded_young"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_models_and_get_best_params(X_train_encoded, y):\n",
    "\n",
    "    def optimize_xgboost(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 5)\n",
    "        }\n",
    "        model = XGBClassifier(**params, random_state=42, eval_metric=\"logloss\")\n",
    "        scores = cross_val_score(model, X_train_encoded, y, cv=5, scoring=\"roc_auc\")\n",
    "        return np.mean(scores)\n",
    "\n",
    "\n",
    "    def optimize_lightgbm(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 50),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "        }\n",
    "        model = LGBMClassifier(**params, random_state=42)\n",
    "        scores = cross_val_score(model, X_train_encoded, y, cv=5, scoring=\"roc_auc\")  \n",
    "        return np.mean(scores)\n",
    "\n",
    "    def optimize_random_forest(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 3, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4)\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "        scores = cross_val_score(model, X_train_encoded, y, cv=5, scoring=\"roc_auc\")  \n",
    "        return np.mean(scores)\n",
    "\n",
    "    # Optuna 스터디 실행\n",
    "    print(\"Optimizing XGBoost...\")\n",
    "    xgb_study = optuna.create_study(direction=\"maximize\")\n",
    "    xgb_study.optimize(optimize_xgboost, n_trials=100)\n",
    "    best_xgb_params = xgb_study.best_params\n",
    "\n",
    "    print(\"Optimizing LightGBM...\")\n",
    "    lgbm_study = optuna.create_study(direction=\"maximize\")\n",
    "    lgbm_study.optimize(optimize_lightgbm, n_trials=100)\n",
    "    best_lgbm_params = lgbm_study.best_params\n",
    "\n",
    "    print(\"Optimizing RandomForest...\")\n",
    "    rf_study = optuna.create_study(direction=\"maximize\")\n",
    "    rf_study.optimize(optimize_random_forest, n_trials=10)\n",
    "    best_rf_params = rf_study.best_params\n",
    "\n",
    "    params = [best_xgb_params, best_lgbm_params, best_rf_params]\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def optimize_models_and_get_best_params_v2(X_train_encoded, y):\n",
    "\n",
    "    def optimize_logistic_regression(trial):\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.01, 10.0, log=True),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "            \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "        }\n",
    "        model = LogisticRegression(**params, random_state=42)\n",
    "        scores = cross_val_score(model, X_train_encoded, y, cv=5, scoring=\"roc_auc\")\n",
    "        return np.mean(scores)\n",
    "\n",
    "    def optimize_random_forest(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 3, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4)\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "        scores = cross_val_score(model, X_train_encoded, y, cv=5, scoring=\"roc_auc\")  \n",
    "        return np.mean(scores)\n",
    "\n",
    "    def optimize_xgboost(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 5)\n",
    "        }\n",
    "        model = XGBClassifier(**params, random_state=42, eval_metric=\"logloss\")\n",
    "        scores = cross_val_score(model, X_train_encoded, y, cv=5, scoring=\"roc_auc\")\n",
    "        return np.mean(scores)\n",
    "\n",
    "    # Optuna 스터디 실행\n",
    "    print(\"Optimizing Logistic Regression...\")\n",
    "    logreg_study = optuna.create_study(direction=\"maximize\")\n",
    "    logreg_study.optimize(optimize_logistic_regression, n_trials=50)\n",
    "    best_logreg_params = logreg_study.best_params\n",
    "\n",
    "    print(\"Optimizing Random Forest...\")\n",
    "    rf_study = optuna.create_study(direction=\"maximize\")\n",
    "    rf_study.optimize(optimize_random_forest, n_trials=10)\n",
    "    best_rf_params = rf_study.best_params\n",
    "\n",
    "    print(\"Optimizing XGBoost...\")\n",
    "    xgb_study = optuna.create_study(direction=\"maximize\")\n",
    "    xgb_study.optimize(optimize_xgboost, n_trials=50)\n",
    "    best_xgb_params = xgb_study.best_params\n",
    "\n",
    "    params = [best_logreg_params, best_rf_params, best_xgb_params]\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble_model(X_train_encoded, y, X_test_encoded, params):\n",
    "\n",
    "    \n",
    "    # best params\n",
    "    best_xgb_params, best_lgbm_params, best_rf_params = params\n",
    "\n",
    "    # 최적화된 모델 생성\n",
    "    xgb_model = XGBClassifier(**best_xgb_params, random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    lgbm_model = LGBMClassifier(**best_lgbm_params, random_state=42)\n",
    "    rf_model = RandomForestClassifier(**best_rf_params, random_state=42)\n",
    "\n",
    "    # Soft Voting 앙상블\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"xgb\", xgb_model),\n",
    "            (\"lgbm\", lgbm_model),\n",
    "            (\"rf\", rf_model)\n",
    "        ],\n",
    "        voting=\"soft\"\n",
    "    )\n",
    "\n",
    "    # 전체 데이터로 학습\n",
    "    ensemble_model.fit(X_train_encoded, y)\n",
    "\n",
    "    pred_proba = ensemble_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "       'probability': pred_proba,\n",
    "       'idx': X_test_encoded['idx']\n",
    "   })\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "def train_ensemble_model_v2(X_train_encoded, y, X_test_encoded, params):\n",
    "\n",
    "    # best params\n",
    "    best_logreg_params, best_rf_params, best_xgb_params = params\n",
    "\n",
    "    # 최적화된 모델 생성\n",
    "    logreg_model = LogisticRegression(**best_logreg_params, random_state=42)\n",
    "    rf_model = RandomForestClassifier(**best_rf_params, random_state=42)\n",
    "    xgb_model = XGBClassifier(**best_xgb_params, random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "\n",
    "    # Soft Voting 앙상블\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"logreg\", logreg_model),\n",
    "            (\"rf\", rf_model),\n",
    "            (\"xgb\", xgb_model)\n",
    "        ],\n",
    "        voting=\"soft\"\n",
    "    )\n",
    "\n",
    "    # 전체 데이터로 학습\n",
    "    ensemble_model.fit(X_train_encoded, y)\n",
    "\n",
    "    # 예측 확률\n",
    "    pred_proba = ensemble_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "    # 제출용 데이터프레임 생성\n",
    "    submission = pd.DataFrame({\n",
    "       'probability': pred_proba,\n",
    "       'idx': X_test_encoded['idx']\n",
    "    })\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def this_func_is_all_you_need(train, test):\n",
    "    # missing_value_removal_function 사용\n",
    "    train_young, train_middle, train_old, train_unknown = missing_value_removal_function(train)\n",
    "    test_young, test_middle, test_old, test_unknown = missing_value_removal_function(test)\n",
    "\n",
    "    X_train_encoded_young, X_test_encoded_young, y_young = data_preprocessing(train_young, test_young)\n",
    "    X_train_encoded_middle, X_test_encoded_middle, y_middle = data_preprocessing(train_middle, test_middle)\n",
    "    X_train_encoded_old, X_test_encoded_old, y_old = data_preprocessing(train_old, test_old)\n",
    "\n",
    "    params_young = optimize_models_and_get_best_params_v2(X_train_encoded_young, y_young)\n",
    "    params_middle = optimize_models_and_get_best_params_v2(X_train_encoded_middle, y_middle)\n",
    "    params_old = optimize_models_and_get_best_params_v2(X_train_encoded_old, y_old)\n",
    "\n",
    "    submission_young = train_ensemble_model_v2(X_train_encoded_young, y_young, X_test_encoded_young, params_young)\n",
    "    submission_middle = train_ensemble_model_v2(X_train_encoded_middle, y_middle, X_test_encoded_middle, params_middle)\n",
    "    submission_old = train_ensemble_model_v2(X_train_encoded_old, y_old, X_test_encoded_old, params_old)\n",
    "\n",
    "    # test_unknown의 데이터 개수만큼 0으로 채워진 submission_unknown 생성\n",
    "    submission_unknown = pd.DataFrame({\n",
    "        'probability': [0] * len(test_unknown),\n",
    "        'idx': test_unknown['idx']\n",
    "    })\n",
    "\n",
    "    submission = pd.concat([submission_young, submission_middle, submission_old, submission_unknown])\n",
    "\n",
    "    submission = submission.sort_values('idx').reset_index(drop=True)\n",
    "    submission = submission.drop(columns=['idx'])\n",
    "\n",
    "    submission['ID'] = [f\"TEST_{i:05d}\" for i in range(len(submission))]\n",
    "\n",
    "    submission = submission[['ID', 'probability']]\n",
    "\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 train 데이터 로드\n",
    "train = pd.read_csv(\"../shared codes/data/train.csv\")\n",
    "test = pd.read_csv(\"../shared codes/data/test.csv\")\n",
    "\n",
    "this_func_is_all_you_need(train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg_aimers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
